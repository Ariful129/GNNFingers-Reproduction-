{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToagHaqb2rMz",
        "outputId": "bc7945c2-6bc5-45c3-a406-289da3673195"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "CELL 1: Installing Dependencies and Creating Folder Structure\n",
            "======================================================================\n",
            "Installing packages...\n",
            "\n",
            "✓ Directory structure created:\n",
            "  /content/gnnfingers_link_prediction/\n",
            "    ├── data/\n",
            "    ├── models/\n",
            "    │   ├── target/\n",
            "    │   ├── positive/\n",
            "    │   └── negative/\n",
            "    ├── fingerprints/\n",
            "    ├── verifier/\n",
            "    └── results/\n",
            "\n",
            "✓ Dependencies installed and directories ready\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "GNNFingers - Link Prediction on Cora Dataset\n",
        "=============================================\n",
        "\n",
        "\n",
        "PIPELINE:\n",
        "1. Load Cora dataset (for link prediction)\n",
        "2. Train target GCN model for link prediction\n",
        "3. Generate 2 positive models (fine-tuned clones)\n",
        "4. Generate 2 negative models (fresh GCN and GraphSAGE)\n",
        "5. Create 5 synthetic fingerprints (random small graphs)\n",
        "6. Collect model responses (edge predictions)\n",
        "7. Train verifier (binary classifier)\n",
        "8. Evaluate: TP, TN, Accuracy\n",
        "\"\"\"\n",
        "\n",
        "# ============================================================================\n",
        "# CELL 1: Setup and Install Dependencies\n",
        "# ============================================================================\n",
        "print(\"=\" * 70)\n",
        "print(\"CELL 1: Installing Dependencies and Creating Folder Structure\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "print(\"Installing packages...\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
        "                       \"torch\", \"torch_geometric\", \"torch_scatter\", \"torch_sparse\"])\n",
        "\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "# Create base directory for link prediction\n",
        "base_dir = Path(\"/content/gnnfingers_link_prediction\")\n",
        "base_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Create subdirectories\n",
        "(base_dir / \"data\").mkdir(exist_ok=True)\n",
        "(base_dir / \"models\" / \"target\").mkdir(parents=True, exist_ok=True)\n",
        "(base_dir / \"models\" / \"positive\").mkdir(parents=True, exist_ok=True)\n",
        "(base_dir / \"models\" / \"negative\").mkdir(parents=True, exist_ok=True)\n",
        "(base_dir / \"fingerprints\").mkdir(exist_ok=True)\n",
        "(base_dir / \"verifier\").mkdir(exist_ok=True)\n",
        "(base_dir / \"results\").mkdir(exist_ok=True)\n",
        "\n",
        "print(f\"\\n✓ Directory structure created:\")\n",
        "print(f\"  {base_dir}/\")\n",
        "print(f\"    ├── data/\")\n",
        "print(f\"    ├── models/\")\n",
        "print(f\"    │   ├── target/\")\n",
        "print(f\"    │   ├── positive/\")\n",
        "print(f\"    │   └── negative/\")\n",
        "print(f\"    ├── fingerprints/\")\n",
        "print(f\"    ├── verifier/\")\n",
        "print(f\"    └── results/\\n\")\n",
        "\n",
        "# Set random seeds\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"✓ Dependencies installed and directories ready\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCgBXuMiBk4H",
        "outputId": "59146617-7653-4be0-8a68-61ed81c91d8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "CELL 2: Define Link Prediction Models\n",
            "======================================================================\n",
            "✓ Link Prediction models and utilities defined\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 2: Define Link Prediction Models and Utilities\n",
        "# ============================================================================\n",
        "print(\"=\" * 70)\n",
        "print(\"CELL 2: Define Link Prediction Models\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "from torch_geometric.nn import GCNConv, SAGEConv\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.utils import negative_sampling, train_test_split_edges\n",
        "\n",
        "class LinkPredictorGCN(nn.Module):\n",
        "    \"\"\"GCN for Link Prediction with edge decoder\"\"\"\n",
        "    def __init__(self, in_channels, hidden_channels=64):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "\n",
        "    def encode(self, x, edge_index):\n",
        "        \"\"\"Get node embeddings\"\"\"\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "    def decode(self, z, edge_index):\n",
        "        \"\"\"Predict edge probabilities from node embeddings\"\"\"\n",
        "        # Dot product decoder: edge_score = z_u · z_v\n",
        "        src, dst = edge_index\n",
        "        return (z[src] * z[dst]).sum(dim=1)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        \"\"\"Full forward pass for link prediction\"\"\"\n",
        "        z = self.encode(x, edge_index)\n",
        "        return z\n",
        "\n",
        "class LinkPredictorSAGE(nn.Module):\n",
        "    \"\"\"GraphSAGE for Link Prediction\"\"\"\n",
        "    def __init__(self, in_channels, hidden_channels=64):\n",
        "        super().__init__()\n",
        "        self.sage1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.sage2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "\n",
        "    def encode(self, x, edge_index):\n",
        "        \"\"\"Get node embeddings\"\"\"\n",
        "        x = self.sage1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.sage2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "    def decode(self, z, edge_index):\n",
        "        \"\"\"Predict edge probabilities\"\"\"\n",
        "        src, dst = edge_index\n",
        "        return (z[src] * z[dst]).sum(dim=1)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        \"\"\"Full forward pass\"\"\"\n",
        "        z = self.encode(x, edge_index)\n",
        "        return z\n",
        "\n",
        "class Verifier(nn.Module):\n",
        "    \"\"\"Binary classifier verifier\"\"\"\n",
        "    def __init__(self, input_dim, hidden_dim=32):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, 16)\n",
        "        self.fc3 = nn.Linear(16, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = torch.sigmoid(self.fc3(x))\n",
        "        return x.squeeze()\n",
        "\n",
        "def load_dataset_link_prediction(dataset_name=\"Cora\"):\n",
        "    \"\"\"Load dataset and prepare for link prediction\"\"\"\n",
        "    dataset = Planetoid(root=str(base_dir / \"data\"), name=dataset_name)\n",
        "    data = dataset[0]\n",
        "\n",
        "    # Split edges into train/val/test for link prediction\n",
        "    data = train_test_split_edges(data, val_ratio=0.05, test_ratio=0.1)\n",
        "\n",
        "    return data, dataset\n",
        "\n",
        "def get_link_labels(pos_edge_index, neg_edge_index):\n",
        "    \"\"\"Create labels for positive and negative edges\"\"\"\n",
        "    num_pos = pos_edge_index.size(1)\n",
        "    num_neg = neg_edge_index.size(1)\n",
        "\n",
        "    link_labels = torch.cat([torch.ones(num_pos), torch.zeros(num_neg)])\n",
        "    return link_labels\n",
        "\n",
        "def train_link_predictor(model, data, epochs=50, lr=0.001, verbose=True):\n",
        "    \"\"\"Train a link prediction model\"\"\"\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Get node embeddings\n",
        "        z = model.encode(data.x, data.train_pos_edge_index)\n",
        "\n",
        "        # Positive edges\n",
        "        pos_pred = model.decode(z, data.train_pos_edge_index)\n",
        "\n",
        "        # Negative sampling\n",
        "        neg_edge_index = negative_sampling(\n",
        "            edge_index=data.train_pos_edge_index,\n",
        "            num_nodes=data.num_nodes,\n",
        "            num_neg_samples=data.train_pos_edge_index.size(1)\n",
        "        )\n",
        "        neg_pred = model.decode(z, neg_edge_index)\n",
        "\n",
        "        # Binary cross-entropy loss\n",
        "        loss = -torch.log(torch.sigmoid(pos_pred) + 1e-15).mean() - \\\n",
        "               torch.log(1 - torch.sigmoid(neg_pred) + 1e-15).mean()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if verbose and (epoch + 1) % 10 == 0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                z = model.encode(data.x, data.train_pos_edge_index)\n",
        "\n",
        "                # Test set evaluation\n",
        "                pos_pred = torch.sigmoid(model.decode(z, data.test_pos_edge_index))\n",
        "                neg_pred = torch.sigmoid(model.decode(z, data.test_neg_edge_index))\n",
        "\n",
        "                preds = torch.cat([pos_pred, neg_pred]).cpu().numpy()\n",
        "                labels = torch.cat([torch.ones(data.test_pos_edge_index.size(1)),\n",
        "                                   torch.zeros(data.test_neg_edge_index.size(1))]).cpu().numpy()\n",
        "\n",
        "                auc = roc_auc_score(labels, preds)\n",
        "\n",
        "            print(f\"    Epoch {epoch+1}/{epochs} | Loss: {loss.item():.4f} | Test AUC: {auc:.3f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "print(\"✓ Link Prediction models and utilities defined\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2wyIZ4CBqzt",
        "outputId": "c3cf9a4c-c316-42ae-a56f-fb880e3b3343"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "CELL 3: Load Cora for Link Prediction and Train Target Model\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n",
            "/tmp/ipython-input-3438120229.py:81: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
            "  data = train_test_split_edges(data, val_ratio=0.05, test_ratio=0.1)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset: Cora (Link Prediction)\n",
            "  Total Nodes: 2708\n",
            "  Total Features: 1433\n",
            "  Train Edges: 8976\n",
            "  Val Edges: 263\n",
            "  Test Edges: 527\n",
            "\n",
            "Training TARGET model (GCN for Link Prediction)...\n",
            "    Epoch 10/50 | Loss: 1.1942 | Test AUC: 0.878\n",
            "    Epoch 20/50 | Loss: 0.9511 | Test AUC: 0.896\n",
            "    Epoch 30/50 | Loss: 0.8982 | Test AUC: 0.907\n",
            "    Epoch 40/50 | Loss: 0.8582 | Test AUC: 0.917\n",
            "    Epoch 50/50 | Loss: 0.8521 | Test AUC: 0.918\n",
            "\n",
            "✓ Target model saved to /content/gnnfingers_link_prediction/models/target/gcn_link_target.pt\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 3: Load Dataset and Train Target Model\n",
        "# ============================================================================\n",
        "print(\"=\" * 70)\n",
        "print(\"CELL 3: Load Cora for Link Prediction and Train Target Model\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "dataset_name = \"Cora\"\n",
        "data, dataset = load_dataset_link_prediction(dataset_name)\n",
        "\n",
        "print(f\"\\nDataset: {dataset_name} (Link Prediction)\")\n",
        "print(f\"  Total Nodes: {data.num_nodes}\")\n",
        "print(f\"  Total Features: {data.num_features}\")\n",
        "print(f\"  Train Edges: {data.train_pos_edge_index.size(1)}\")\n",
        "print(f\"  Val Edges: {data.val_pos_edge_index.size(1)}\")\n",
        "print(f\"  Test Edges: {data.test_pos_edge_index.size(1)}\")\n",
        "\n",
        "# Train target model\n",
        "print(f\"\\nTraining TARGET model (GCN for Link Prediction)...\")\n",
        "target_model = LinkPredictorGCN(data.num_features, hidden_channels=64)\n",
        "target_model = train_link_predictor(target_model, data, epochs=50)\n",
        "\n",
        "# Save target model\n",
        "target_path = base_dir / \"models\" / \"target\" / \"gcn_link_target.pt\"\n",
        "torch.save(target_model.state_dict(), target_path)\n",
        "print(f\"\\n✓ Target model saved to {target_path}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSifIyk8BwlE",
        "outputId": "14535e05-8f33-45b0-fbba-8896614d7f8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "CELL 4: Generate Positive Models (Fine-tuned Clones)\n",
            "======================================================================\n",
            "\n",
            "Creating POSITIVE model 1 (fine-tuned clone)...\n",
            "  ✓ Saved to /content/gnnfingers_link_prediction/models/positive/gcn_link_pos_0.pt\n",
            "\n",
            "Creating POSITIVE model 2 (fine-tuned clone)...\n",
            "  ✓ Saved to /content/gnnfingers_link_prediction/models/positive/gcn_link_pos_1.pt\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 4: Generate 2 Positive Models (Fine-tuned)\n",
        "# ============================================================================\n",
        "print(\"=\" * 70)\n",
        "print(\"CELL 4: Generate Positive Models (Fine-tuned Clones)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "def clone_and_finetune_link(model, data, seed, finetune_epochs=10, lr=0.0001):\n",
        "    \"\"\"Clone target link predictor and fine-tune it\"\"\"\n",
        "    torch.manual_seed(seed)\n",
        "    cloned = LinkPredictorGCN(data.num_features, hidden_channels=64)\n",
        "    cloned.load_state_dict(model.state_dict())\n",
        "\n",
        "    optimizer = torch.optim.Adam(cloned.parameters(), lr=lr)\n",
        "\n",
        "    for _ in range(finetune_epochs):\n",
        "        cloned.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        z = cloned.encode(data.x, data.train_pos_edge_index)\n",
        "        pos_pred = cloned.decode(z, data.train_pos_edge_index)\n",
        "\n",
        "        neg_edge_index = negative_sampling(\n",
        "            edge_index=data.train_pos_edge_index,\n",
        "            num_nodes=data.num_nodes,\n",
        "            num_neg_samples=data.train_pos_edge_index.size(1)\n",
        "        )\n",
        "        neg_pred = cloned.decode(z, neg_edge_index)\n",
        "\n",
        "        loss = -torch.log(torch.sigmoid(pos_pred) + 1e-15).mean() - \\\n",
        "               torch.log(1 - torch.sigmoid(neg_pred) + 1e-15).mean()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return cloned\n",
        "\n",
        "positive_models = []\n",
        "positive_paths = []\n",
        "\n",
        "for i in range(2):\n",
        "    print(f\"\\nCreating POSITIVE model {i+1} (fine-tuned clone)...\")\n",
        "    pos_model = clone_and_finetune_link(target_model, data, seed=100+i, finetune_epochs=10)\n",
        "    positive_models.append(pos_model)\n",
        "\n",
        "    # Save model\n",
        "    pos_path = base_dir / \"models\" / \"positive\" / f\"gcn_link_pos_{i}.pt\"\n",
        "    torch.save(pos_model.state_dict(), pos_path)\n",
        "    positive_paths.append(pos_path)\n",
        "    print(f\"  ✓ Saved to {pos_path}\")\n",
        "\n",
        "print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGdZ1L2ABz8s",
        "outputId": "652d96fd-1f85-4db3-e7cb-38a3037be6d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "CELL 5: Generate Negative Models (Independent Training)\n",
            "======================================================================\n",
            "\n",
            "Creating NEGATIVE model 1 (fresh GCN, different seed)...\n",
            "  ✓ Saved to /content/gnnfingers_link_prediction/models/negative/gcn_link_neg_0.pt\n",
            "\n",
            "Creating NEGATIVE model 2 (GraphSAGE, different architecture)...\n",
            "  ✓ Saved to /content/gnnfingers_link_prediction/models/negative/sage_link_neg_1.pt\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 5: Generate 2 Negative Models (Independent)\n",
        "# ============================================================================\n",
        "print(\"=\" * 70)\n",
        "print(\"CELL 5: Generate Negative Models (Independent Training)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "negative_models = []\n",
        "negative_paths = []\n",
        "\n",
        "# Negative 1: Fresh GCN\n",
        "print(\"\\nCreating NEGATIVE model 1 (fresh GCN, different seed)...\")\n",
        "torch.manual_seed(200)\n",
        "neg_model_1 = LinkPredictorGCN(data.num_features, hidden_channels=64)\n",
        "neg_model_1 = train_link_predictor(neg_model_1, data, epochs=50, verbose=False)\n",
        "negative_models.append(neg_model_1)\n",
        "\n",
        "neg_path_1 = base_dir / \"models\" / \"negative\" / \"gcn_link_neg_0.pt\"\n",
        "torch.save(neg_model_1.state_dict(), neg_path_1)\n",
        "negative_paths.append(neg_path_1)\n",
        "print(f\"  ✓ Saved to {neg_path_1}\\n\")\n",
        "\n",
        "# Negative 2: GraphSAGE\n",
        "print(\"Creating NEGATIVE model 2 (GraphSAGE, different architecture)...\")\n",
        "torch.manual_seed(201)\n",
        "neg_model_2 = LinkPredictorSAGE(data.num_features, hidden_channels=64)\n",
        "neg_model_2 = train_link_predictor(neg_model_2, data, epochs=50, verbose=False)\n",
        "negative_models.append(neg_model_2)\n",
        "\n",
        "neg_path_2 = base_dir / \"models\" / \"negative\" / \"sage_link_neg_1.pt\"\n",
        "torch.save(neg_model_2.state_dict(), neg_path_2)\n",
        "negative_paths.append(neg_path_2)\n",
        "print(f\"  ✓ Saved to {neg_path_2}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ja3TLdhkB7ml",
        "outputId": "5e83b8e8-c96c-4630-8f86-b75d90342da5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "CELL 6: Create Synthetic Fingerprints for Link Prediction\n",
            "======================================================================\n",
            "\n",
            "Creating 5 random fingerprints...\n",
            "  ✓ FP 1: nodes=16, edges=26\n",
            "  ✓ FP 2: nodes=16, edges=27\n",
            "  ✓ FP 3: nodes=16, edges=23\n",
            "  ✓ FP 4: nodes=16, edges=25\n",
            "  ✓ FP 5: nodes=16, edges=25\n",
            "\n",
            "✓ Fingerprints saved to /content/gnnfingers_link_prediction/fingerprints/fingerprints.pt\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 6: Create Synthetic Fingerprints (Small Graphs)\n",
        "# ============================================================================\n",
        "print(\"=\" * 70)\n",
        "print(\"CELL 6: Create Synthetic Fingerprints for Link Prediction\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "num_fingerprints = 5\n",
        "nodes_per_fp = 16\n",
        "\n",
        "def create_random_fingerprint(num_nodes, num_features, sparsity=0.3):\n",
        "    \"\"\"Create random synthetic graph fingerprint\"\"\"\n",
        "    # Random node features\n",
        "    x = torch.randn(num_nodes, num_features)\n",
        "\n",
        "    # Random sparse edges\n",
        "    num_possible_edges = num_nodes * (num_nodes - 1) // 2\n",
        "    num_edges = max(1, int(num_possible_edges * sparsity))\n",
        "\n",
        "    edge_pairs = []\n",
        "    for _ in range(num_edges):\n",
        "        u = np.random.randint(0, num_nodes)\n",
        "        v = np.random.randint(0, num_nodes)\n",
        "        if u != v and [u, v] not in edge_pairs and [v, u] not in edge_pairs:\n",
        "            edge_pairs.append([u, v])\n",
        "\n",
        "    if edge_pairs:\n",
        "        edge_index = torch.tensor(edge_pairs, dtype=torch.long).t().contiguous()\n",
        "    else:\n",
        "        edge_index = torch.zeros((2, 0), dtype=torch.long)\n",
        "\n",
        "    return x, edge_index\n",
        "\n",
        "fingerprints = []\n",
        "print(f\"\\nCreating {num_fingerprints} random fingerprints...\")\n",
        "\n",
        "for i in range(num_fingerprints):\n",
        "    x, edge_index = create_random_fingerprint(nodes_per_fp, data.num_features, sparsity=0.25)\n",
        "    fingerprints.append((x, edge_index))\n",
        "    print(f\"  ✓ FP {i+1}: nodes={x.shape[0]}, edges={edge_index.shape[1]}\")\n",
        "\n",
        "# Save fingerprints\n",
        "fp_path = base_dir / \"fingerprints\" / \"fingerprints.pt\"\n",
        "torch.save(fingerprints, fp_path)\n",
        "print(f\"\\n✓ Fingerprints saved to {fp_path}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqBbNTqzCNH2",
        "outputId": "bc809f56-7407-4401-ed60-3c7c5e93beb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "CELL 7: Collect Model Response Vectors (Edge Predictions)\n",
            "======================================================================\n",
            "\n",
            "Collecting link prediction responses from TARGET model...\n",
            "Collecting responses from POSITIVE model 0...\n",
            "Collecting responses from POSITIVE model 1...\n",
            "Collecting responses from NEGATIVE model 0...\n",
            "Collecting responses from NEGATIVE model 1...\n",
            "\n",
            "✓ Response vector dimension: 44\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 7: Collect Model Response Vectors (Edge Predictions)\n",
        "# ============================================================================\n",
        "print(\"=\" * 70)\n",
        "print(\"CELL 7: Collect Model Response Vectors (Edge Predictions)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "def get_link_response_vector(model, fingerprints, num_edge_samples=10):\n",
        "    \"\"\"\n",
        "    Query model on fingerprints and collect edge prediction responses.\n",
        "    For link prediction, we sample node pairs and predict edge scores.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    responses = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for fp_x, fp_edge in fingerprints:\n",
        "            # Get node embeddings from fingerprint\n",
        "            z = model.encode(fp_x, fp_edge)\n",
        "\n",
        "            # Sample random node pairs (potential edges)\n",
        "            num_nodes = fp_x.shape[0]\n",
        "            sampled_edges = []\n",
        "\n",
        "            for _ in range(min(num_edge_samples, num_nodes * (num_nodes - 1) // 4)):\n",
        "                u = np.random.randint(0, num_nodes)\n",
        "                v = np.random.randint(0, num_nodes)\n",
        "                if u != v:\n",
        "                    sampled_edges.append([u, v])\n",
        "\n",
        "            if sampled_edges:\n",
        "                sampled_edge_index = torch.tensor(sampled_edges, dtype=torch.long).t()\n",
        "                edge_scores = model.decode(z, sampled_edge_index)\n",
        "                responses.append(edge_scores.flatten())\n",
        "\n",
        "    # Concatenate all responses into one vector\n",
        "    response_vector = torch.cat(responses) if responses else torch.tensor([])\n",
        "    return response_vector\n",
        "\n",
        "# Collect responses from all models\n",
        "all_responses = {}\n",
        "\n",
        "print(\"\\nCollecting link prediction responses from TARGET model...\")\n",
        "all_responses['target'] = get_link_response_vector(target_model, fingerprints)\n",
        "\n",
        "for i, pos_model in enumerate(positive_models):\n",
        "    print(f\"Collecting responses from POSITIVE model {i}...\")\n",
        "    all_responses[f'pos_{i}'] = get_link_response_vector(pos_model, fingerprints)\n",
        "\n",
        "for i, neg_model in enumerate(negative_models):\n",
        "    print(f\"Collecting responses from NEGATIVE model {i}...\")\n",
        "    all_responses[f'neg_{i}'] = get_link_response_vector(neg_model, fingerprints)\n",
        "\n",
        "print(f\"\\n✓ Response vector dimension: {all_responses['target'].shape[0]}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCQnZsldCO81",
        "outputId": "4e4ffb11-fac3-43c7-a2c8-0aad7b4bb866"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "CELL 8: Build Training Data and Train Verifier\n",
            "======================================================================\n",
            "\n",
            "✓ Target model (label=1)\n",
            "✓ Positive model 0 (label=1)\n",
            "✓ Positive model 1 (label=1)\n",
            "✓ Negative model 0 (label=0)\n",
            "✓ Negative model 1 (label=0)\n",
            "\n",
            "Checking tensor shapes before concatenation:\n",
            "  Tensor 0: torch.Size([1, 44])\n",
            "  Tensor 1: torch.Size([1, 46])\n",
            "  Tensor 2: torch.Size([1, 48])\n",
            "  Tensor 3: torch.Size([1, 47])\n",
            "  Tensor 4: torch.Size([1, 48])\n",
            "\n",
            "Training data shape: X=torch.Size([5, 44]), y=torch.Size([5])\n",
            "  Class 1 (positive): 3 samples\n",
            "  Class 0 (negative): 2 samples\n",
            "\n",
            "Training VERIFIER for Link Prediction task...\n",
            "  Epoch 50/200 | Loss: 0.0000\n",
            "  Epoch 100/200 | Loss: 0.0000\n",
            "  Epoch 150/200 | Loss: 0.0000\n",
            "  Epoch 200/200 | Loss: 0.0000\n",
            "\n",
            "✓ Verifier saved to /content/gnnfingers_link_prediction/verifier/verifier_link.pt\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 8: Build Training Data and Train Verifier\n",
        "# ============================================================================\n",
        "print(\"=\" * 70)\n",
        "print(\"CELL 8: Build Training Data and Train Verifier\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Build training dataset for verifier\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "# Positive samples (label = 1)\n",
        "X_train.append(all_responses['target'].unsqueeze(0))\n",
        "y_train.append(1)\n",
        "print(\"\\n✓ Target model (label=1)\")\n",
        "\n",
        "for i in range(len(positive_models)):\n",
        "    X_train.append(all_responses[f'pos_{i}'].unsqueeze(0))\n",
        "    y_train.append(1)\n",
        "    print(f\"✓ Positive model {i} (label=1)\")\n",
        "\n",
        "# Negative samples (label = 0)\n",
        "for i in range(len(negative_models)):\n",
        "    X_train.append(all_responses[f'neg_{i}'].unsqueeze(0))\n",
        "    y_train.append(0)\n",
        "    print(f\"✓ Negative model {i} (label=0)\")\n",
        "\n",
        "# Debug shapes\n",
        "print(\"\\nChecking tensor shapes before concatenation:\")\n",
        "for i, x in enumerate(X_train):\n",
        "    print(f\"  Tensor {i}: {x.shape}\")\n",
        "\n",
        "# Ensure all same feature dimension\n",
        "min_dim = min(x.shape[1] if x.ndim > 1 else x.shape[0] for x in X_train)\n",
        "X_train = [x[:, :min_dim] if x.shape[1] > min_dim else\n",
        "           torch.nn.functional.pad(x, (0, min_dim - x.shape[1]))\n",
        "           for x in X_train]\n",
        "\n",
        "X_train = torch.cat(X_train, dim=0)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "\n",
        "print(f\"\\nTraining data shape: X={X_train.shape}, y={y_train.shape}\")\n",
        "print(f\"  Class 1 (positive): {(y_train == 1).sum()} samples\")\n",
        "print(f\"  Class 0 (negative): {(y_train == 0).sum()} samples\")\n",
        "\n",
        "# Train verifier\n",
        "print(f\"\\nTraining VERIFIER for Link Prediction task...\")\n",
        "verifier = Verifier(input_dim=X_train.shape[1], hidden_dim=32)\n",
        "optimizer = torch.optim.Adam(verifier.parameters(), lr=0.01)\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "num_epochs = 200\n",
        "for epoch in range(num_epochs):\n",
        "    verifier.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    y_pred = verifier(X_train)\n",
        "    loss = loss_fn(y_pred, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 50 == 0:\n",
        "        print(f\"  Epoch {epoch+1}/{num_epochs} | Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Save verifier\n",
        "verifier_path = base_dir / \"verifier\" / \"verifier_link.pt\"\n",
        "torch.save(verifier.state_dict(), verifier_path)\n",
        "print(f\"\\n✓ Verifier saved to {verifier_path}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiXnlVidCsrF",
        "outputId": "2249a469-75bd-402b-9fb4-acf64a63d519"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "CELL 9: EVALUATE VERIFIER - Calculate TP/TN/Accuracy\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "CONFUSION MATRIX\n",
            "======================================================================\n",
            "  TP (True Positive):   3   ← Positive models correctly identified\n",
            "  TN (True Negative):   2   ← Negative models correctly identified\n",
            "  FP (False Positive):  0   ← Negative incorrectly as positive\n",
            "  FN (False Negative):  0   ← Positive incorrectly as negative\n",
            "\n",
            "======================================================================\n",
            "METRICS\n",
            "======================================================================\n",
            "  Accuracy:   1.000  (TP+TN)/Total = (3+2)/5\n",
            "  Precision:  1.000  TP/(TP+FP) = 3/(3+0)\n",
            "  Recall:     1.000   TP/(TP+FN) = 3/(3+0)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 9: Evaluate Verifier and Calculate Metrics\n",
        "# ============================================================================\n",
        "print(\"=\" * 70)\n",
        "print(\"CELL 9: EVALUATE VERIFIER - Calculate TP/TN/Accuracy\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "verifier.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred_probs = verifier(X_train)\n",
        "    y_pred = (y_pred_probs >= 0.5).long()\n",
        "    y_true = y_train.long()\n",
        "\n",
        "# Calculate confusion matrix\n",
        "TP = ((y_pred == 1) & (y_true == 1)).sum().item()\n",
        "TN = ((y_pred == 0) & (y_true == 0)).sum().item()\n",
        "FP = ((y_pred == 1) & (y_true == 0)).sum().item()\n",
        "FN = ((y_pred == 0) & (y_true == 1)).sum().item()\n",
        "\n",
        "total = len(y_true)\n",
        "accuracy = (TP + TN) / total\n",
        "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CONFUSION MATRIX\")\n",
        "print(\"=\"*70)\n",
        "print(f\"  TP (True Positive):   {TP}   ← Positive models correctly identified\")\n",
        "print(f\"  TN (True Negative):   {TN}   ← Negative models correctly identified\")\n",
        "print(f\"  FP (False Positive):  {FP}   ← Negative incorrectly as positive\")\n",
        "print(f\"  FN (False Negative):  {FN}   ← Positive incorrectly as negative\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"METRICS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"  Accuracy:   {accuracy:.3f}  (TP+TN)/Total = ({TP}+{TN})/{total}\")\n",
        "print(f\"  Precision:  {precision:.3f}  TP/(TP+FP) = {TP}/({TP}+{FP})\")\n",
        "print(f\"  Recall:     {recall:.3f}   TP/(TP+FN) = {TP}/({TP}+{FN})\")\n",
        "print()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
