{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbkEnQIu3Vct",
        "outputId": "acbe47a6-af78-424a-da4f-0d9b1c0c6821"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CELL 1: Installing dependencies...\n",
            "✓ Directory structure created at /content/gnnfingers\n",
            "\n",
            "✓ Dependencies installed and directories ready\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\"\"\"\n",
        "GNNFingers Structured Implementation for Google Colab\n",
        "======================================================\n",
        "\n",
        "\n",
        "STRUCTURE:\n",
        "  gnnfingers/\n",
        "    ├── data/              (Cora, Citeseer datasets)\n",
        "    ├── models/\n",
        "    │   ├── target/        (target model checkpoint)\n",
        "    │   ├── positive/      (positive models)\n",
        "    │   └── negative/      (negative models)\n",
        "    ├── fingerprints/      (saved fingerprints)\n",
        "    ├── verifier/          (trained verifier)\n",
        "    ├── results/           (TP/TN/accuracy logs)\n",
        "    └── manifest.csv       (tracking file)\n",
        "\n",
        "RUN IN COLAB: Copy each cell below into separate Colab cells in order.\n",
        "\"\"\"\n",
        "\n",
        "# ============================================================================\n",
        "# CELL 1: Setup and Install Dependencies\n",
        "# ============================================================================\n",
        "print(\"CELL 1: Installing dependencies...\")\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
        "                       \"torch\", \"torch_geometric\", \"torch_scatter\", \"torch_sparse\"])\n",
        "\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Create base directory\n",
        "base_dir = Path(\"/content/gnnfingers\")\n",
        "base_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Create subdirectories\n",
        "(base_dir / \"data\").mkdir(exist_ok=True)\n",
        "(base_dir / \"models\" / \"target\").mkdir(parents=True, exist_ok=True)\n",
        "(base_dir / \"models\" / \"positive\").mkdir(parents=True, exist_ok=True)\n",
        "(base_dir / \"models\" / \"negative\").mkdir(parents=True, exist_ok=True)\n",
        "(base_dir / \"fingerprints\").mkdir(exist_ok=True)\n",
        "(base_dir / \"verifier\").mkdir(exist_ok=True)\n",
        "(base_dir / \"results\").mkdir(exist_ok=True)\n",
        "\n",
        "print(f\"✓ Directory structure created at {base_dir}\\n\")\n",
        "\n",
        "# Set seeds\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"✓ Dependencies installed and directories ready\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBqMD3L6JJMW",
        "outputId": "8f4ed89e-d8a7-4e8a-8b4b-cdaf526cfc08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CELL 2: Define Models and Utilities...\n",
            "✓ Models and utilities defined\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 2: Define Models and Dataset Utilities\n",
        "# ============================================================================\n",
        "print(\"CELL 2: Define Models and Utilities...\")\n",
        "\n",
        "from torch_geometric.nn import GCNConv, SAGEConv\n",
        "from torch_geometric.datasets import Planetoid\n",
        "\n",
        "class GCNModel(nn.Module):\n",
        "    \"\"\"Graph Convolutional Network\"\"\"\n",
        "    def __init__(self, in_channels, hidden_channels=64, out_channels=7):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "class GraphSAGEModel(nn.Module):\n",
        "    \"\"\"GraphSAGE Model\"\"\"\n",
        "    def __init__(self, in_channels, hidden_channels=64, out_channels=7):\n",
        "        super().__init__()\n",
        "        self.sage1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.sage2 = SAGEConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.sage1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.sage2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "class Verifier(nn.Module):\n",
        "    \"\"\"Binary classifier verifier\"\"\"\n",
        "    def __init__(self, input_dim, hidden_dim=32):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, 16)\n",
        "        self.fc3 = nn.Linear(16, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = torch.sigmoid(self.fc3(x))\n",
        "        return x.squeeze()\n",
        "\n",
        "def load_dataset(dataset_name=\"Cora\"):\n",
        "    \"\"\"Load Cora or Citeseer dataset\"\"\"\n",
        "    dataset = Planetoid(root=str(base_dir / \"data\"), name=dataset_name)\n",
        "    data = dataset[0]\n",
        "    return data, dataset\n",
        "\n",
        "def train_model(model, data, epochs=50, lr=0.001, verbose=True):\n",
        "    \"\"\"Train a model on Cora/Citeseer\"\"\"\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x, data.edge_index)\n",
        "        loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if verbose and (epoch + 1) % 10 == 0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                pred = model(data.x, data.edge_index).argmax(dim=1)\n",
        "                test_acc = accuracy_score(data.y[data.test_mask].numpy(),\n",
        "                                         pred[data.test_mask].numpy())\n",
        "            print(f\"    Epoch {epoch+1}/{epochs} | Test Acc: {test_acc:.3f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "print(\"✓ Models and utilities defined\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irOJXkAzKPI0",
        "outputId": "dadd7b0a-81d1-411c-d238-2363405f5cf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CELL 3: Load Dataset and Train Target Model...\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: Citeseer\n",
            "  Nodes: 3327\n",
            "  Edges: 9104\n",
            "  Features: 3703\n",
            "  Classes: 6\n",
            "\n",
            "Training TARGET model (GCN)...\n",
            "    Epoch 10/50 | Test Acc: 0.553\n",
            "    Epoch 20/50 | Test Acc: 0.636\n",
            "    Epoch 30/50 | Test Acc: 0.649\n",
            "    Epoch 40/50 | Test Acc: 0.652\n",
            "    Epoch 50/50 | Test Acc: 0.657\n",
            "✓ Target model saved to /content/gnnfingers/models/target/gcn_target.pt\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 3: Load Dataset and Train Target Model\n",
        "# ============================================================================\n",
        "print(\"CELL 3: Load Dataset and Train Target Model...\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "dataset_name = \"Citeseer\"\n",
        "data, dataset = load_dataset(dataset_name)\n",
        "\n",
        "print(f\"Dataset: {dataset_name}\")\n",
        "print(f\"  Nodes: {data.num_nodes}\")\n",
        "print(f\"  Edges: {data.num_edges}\")\n",
        "print(f\"  Features: {data.num_features}\")\n",
        "print(f\"  Classes: {dataset.num_classes}\\n\")\n",
        "\n",
        "# Train target model\n",
        "print(\"Training TARGET model (GCN)...\")\n",
        "target_model = GCNModel(data.num_features, hidden_channels=64, out_channels=dataset.num_classes)\n",
        "target_model = train_model(target_model, data, epochs=50)\n",
        "\n",
        "# Save target model\n",
        "target_path = base_dir / \"models\" / \"target\" / \"gcn_target.pt\"\n",
        "torch.save(target_model.state_dict(), target_path)\n",
        "print(f\"✓ Target model saved to {target_path}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDymY74BKddd",
        "outputId": "33b004b4-7cb2-415b-f542-b24ed890caa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CELL 4: Generate Positive Models (Fine-tuned Clones)...\n",
            "======================================================================\n",
            "Creating POSITIVE model 1...\n",
            "  ✓ Saved to /content/gnnfingers/models/positive/gcn_pos_0.pt\n",
            "Creating POSITIVE model 2...\n",
            "  ✓ Saved to /content/gnnfingers/models/positive/gcn_pos_1.pt\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 4: Generate 2 Positive Models (Fine-tuned)\n",
        "# ============================================================================\n",
        "print(\"CELL 4: Generate Positive Models (Fine-tuned Clones)...\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "def clone_and_finetune(model, data, seed, finetune_epochs=10, lr=0.0001):\n",
        "    \"\"\"Clone target and fine-tune it\"\"\"\n",
        "    torch.manual_seed(seed)\n",
        "    cloned = GCNModel(data.num_features, hidden_channels=64, out_channels=dataset.num_classes)\n",
        "    cloned.load_state_dict(model.state_dict())\n",
        "\n",
        "    optimizer = torch.optim.Adam(cloned.parameters(), lr=lr)\n",
        "    for _ in range(finetune_epochs):\n",
        "        cloned.train()\n",
        "        optimizer.zero_grad()\n",
        "        out = cloned(data.x, data.edge_index)\n",
        "        loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return cloned\n",
        "\n",
        "positive_models = []\n",
        "positive_paths = []\n",
        "\n",
        "for i in range(2):\n",
        "    print(f\"Creating POSITIVE model {i+1}...\")\n",
        "    pos_model = clone_and_finetune(target_model, data, seed=100+i, finetune_epochs=10)\n",
        "    positive_models.append(pos_model)\n",
        "\n",
        "    # Save\n",
        "    pos_path = base_dir / \"models\" / \"positive\" / f\"gcn_pos_{i}.pt\"\n",
        "    torch.save(pos_model.state_dict(), pos_path)\n",
        "    positive_paths.append(pos_path)\n",
        "    print(f\"  ✓ Saved to {pos_path}\")\n",
        "\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbe7x2MxKhZb",
        "outputId": "87a61c28-a509-4aa5-bbc7-80b8dddf4d84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CELL 5: Generate Negative Models (Independent Training)...\n",
            "======================================================================\n",
            "Creating NEGATIVE model 1 (fresh GCN)...\n",
            "  ✓ Saved to /content/gnnfingers/models/negative/gcn_neg_0.pt\n",
            "\n",
            "Creating NEGATIVE model 2 (GraphSAGE)...\n",
            "  ✓ Saved to /content/gnnfingers/models/negative/sage_neg_1.pt\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 5: Generate 2 Negative Models (Independent)\n",
        "# ============================================================================\n",
        "print(\"CELL 5: Generate Negative Models (Independent Training)...\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "negative_models = []\n",
        "negative_paths = []\n",
        "\n",
        "# Negative 1: Fresh GCN\n",
        "print(\"Creating NEGATIVE model 1 (fresh GCN)...\")\n",
        "torch.manual_seed(200)\n",
        "neg_model_1 = GCNModel(data.num_features, hidden_channels=64, out_channels=dataset.num_classes)\n",
        "neg_model_1 = train_model(neg_model_1, data, epochs=50, verbose=False)\n",
        "negative_models.append(neg_model_1)\n",
        "\n",
        "neg_path_1 = base_dir / \"models\" / \"negative\" / \"gcn_neg_0.pt\"\n",
        "torch.save(neg_model_1.state_dict(), neg_path_1)\n",
        "negative_paths.append(neg_path_1)\n",
        "print(f\"  ✓ Saved to {neg_path_1}\\n\")\n",
        "\n",
        "# Negative 2: GraphSAGE\n",
        "print(\"Creating NEGATIVE model 2 (GraphSAGE)...\")\n",
        "torch.manual_seed(201)\n",
        "neg_model_2 = GraphSAGEModel(data.num_features, hidden_channels=64, out_channels=dataset.num_classes)\n",
        "neg_model_2 = train_model(neg_model_2, data, epochs=50, verbose=False)\n",
        "negative_models.append(neg_model_2)\n",
        "\n",
        "neg_path_2 = base_dir / \"models\" / \"negative\" / \"sage_neg_1.pt\"\n",
        "torch.save(neg_model_2.state_dict(), neg_path_2)\n",
        "negative_paths.append(neg_path_2)\n",
        "print(f\"  ✓ Saved to {neg_path_2}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehu-YIFFKrmM",
        "outputId": "e55b8475-88e1-4cef-e2c9-42ecbfc08023"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CELL 6: Create Synthetic Fingerprints...\n",
            "======================================================================\n",
            "Creating 5 fingerprints...\n",
            "  ✓ FP 1: nodes=16, edges=22\n",
            "  ✓ FP 2: nodes=16, edges=22\n",
            "  ✓ FP 3: nodes=16, edges=23\n",
            "  ✓ FP 4: nodes=16, edges=22\n",
            "  ✓ FP 5: nodes=16, edges=19\n",
            "✓ Fingerprints saved to /content/gnnfingers/fingerprints/fingerprints.pt\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 6: Create Synthetic Fingerprints\n",
        "# ============================================================================\n",
        "print(\"CELL 6: Create Synthetic Fingerprints...\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "num_fingerprints = 5\n",
        "nodes_per_fp = 16\n",
        "\n",
        "def create_random_fingerprint(num_nodes, num_features, sparsity=0.3):\n",
        "    \"\"\"Create random synthetic graph fingerprint\"\"\"\n",
        "    x = torch.randn(num_nodes, num_features)\n",
        "\n",
        "    num_possible_edges = num_nodes * (num_nodes - 1) / 2\n",
        "    num_edges = max(1, int(num_possible_edges * sparsity))\n",
        "\n",
        "    edge_pairs = []\n",
        "    for _ in range(num_edges):\n",
        "        u = np.random.randint(0, num_nodes)\n",
        "        v = np.random.randint(0, num_nodes)\n",
        "        if u != v and [u, v] not in edge_pairs:\n",
        "            edge_pairs.append([u, v])\n",
        "\n",
        "    if edge_pairs:\n",
        "        edge_index = torch.tensor(edge_pairs, dtype=torch.long).t().contiguous()\n",
        "    else:\n",
        "        edge_index = torch.zeros((2, 0), dtype=torch.long)\n",
        "\n",
        "    return x, edge_index\n",
        "\n",
        "fingerprints = []\n",
        "print(f\"Creating {num_fingerprints} fingerprints...\")\n",
        "\n",
        "for i in range(num_fingerprints):\n",
        "    x, edge_index = create_random_fingerprint(nodes_per_fp, data.num_features, sparsity=0.2)\n",
        "    fingerprints.append((x, edge_index))\n",
        "    print(f\"  ✓ FP {i+1}: nodes={x.shape[0]}, edges={edge_index.shape[1]}\")\n",
        "\n",
        "# Save fingerprints\n",
        "fp_path = base_dir / \"fingerprints\" / \"fingerprints.pt\"\n",
        "torch.save(fingerprints, fp_path)\n",
        "print(f\"✓ Fingerprints saved to {fp_path}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrWqtAEyKwo-",
        "outputId": "bcc62a7f-6b83-4831-8c91-6dd913fce054"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CELL 7: Collect Model Response Vectors...\n",
            "======================================================================\n",
            "Collecting responses from TARGET model...\n",
            "Collecting responses from POSITIVE model 0...\n",
            "Collecting responses from POSITIVE model 1...\n",
            "Collecting responses from NEGATIVE model 0...\n",
            "Collecting responses from NEGATIVE model 1...\n",
            "\n",
            "Response vector dimension: 150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 7: Collect Model Response Vectors\n",
        "# ============================================================================\n",
        "print(\"CELL 7: Collect Model Response Vectors...\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "def get_response_vector(model, fingerprints, num_samples=5):\n",
        "    \"\"\"Query model on all fingerprints and collect responses\"\"\"\n",
        "    model.eval()\n",
        "    responses = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for fp_x, fp_edge in fingerprints:\n",
        "            out = model(fp_x, fp_edge)\n",
        "\n",
        "            num_to_sample = min(num_samples, out.shape[0])\n",
        "            sampled_indices = np.random.choice(out.shape[0], num_to_sample, replace=False)\n",
        "            sampled_out = out[sampled_indices].flatten()\n",
        "\n",
        "            responses.append(sampled_out)\n",
        "\n",
        "    response_vector = torch.cat(responses)\n",
        "    return response_vector\n",
        "\n",
        "# Collect all responses\n",
        "all_responses = {}\n",
        "\n",
        "print(\"Collecting responses from TARGET model...\")\n",
        "all_responses['target'] = get_response_vector(target_model, fingerprints)\n",
        "\n",
        "for i, pos_model in enumerate(positive_models):\n",
        "    print(f\"Collecting responses from POSITIVE model {i}...\")\n",
        "    all_responses[f'pos_{i}'] = get_response_vector(pos_model, fingerprints)\n",
        "\n",
        "for i, neg_model in enumerate(negative_models):\n",
        "    print(f\"Collecting responses from NEGATIVE model {i}...\")\n",
        "    all_responses[f'neg_{i}'] = get_response_vector(neg_model, fingerprints)\n",
        "\n",
        "print(f\"\\nResponse vector dimension: {all_responses['target'].shape[0]}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek2NhMATK4UM",
        "outputId": "0e273416-f18a-447f-e383-fb7ec19ed609"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CELL 8: Build Training Data and Train Verifier...\n",
            "======================================================================\n",
            "✓ Target model (label=1)\n",
            "✓ Positive model 0 (label=1)\n",
            "✓ Positive model 1 (label=1)\n",
            "✓ Negative model 0 (label=0)\n",
            "✓ Negative model 1 (label=0)\n",
            "\n",
            "Training data shape: X=torch.Size([5, 150]), y=torch.Size([5])\n",
            "  Class 1 (positive): 3 samples\n",
            "  Class 0 (negative): 2 samples\n",
            "\n",
            "Training VERIFIER...\n",
            "  Epoch 50/200 | Loss: 0.0000\n",
            "  Epoch 100/200 | Loss: 0.0000\n",
            "  Epoch 150/200 | Loss: 0.0000\n",
            "  Epoch 200/200 | Loss: 0.0000\n",
            "✓ Verifier saved to /content/gnnfingers/verifier/verifier.pt\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 8: Build Training Data and Train Verifier\n",
        "# ============================================================================\n",
        "print(\"CELL 8: Build Training Data and Train Verifier...\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Build training dataset\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "# Positive samples (label = 1)\n",
        "X_train.append(all_responses['target'].unsqueeze(0))\n",
        "y_train.append(1)\n",
        "print(\"✓ Target model (label=1)\")\n",
        "\n",
        "for i in range(len(positive_models)):\n",
        "    X_train.append(all_responses[f'pos_{i}'].unsqueeze(0))\n",
        "    y_train.append(1)\n",
        "    print(f\"✓ Positive model {i} (label=1)\")\n",
        "\n",
        "# Negative samples (label = 0)\n",
        "for i in range(len(negative_models)):\n",
        "    X_train.append(all_responses[f'neg_{i}'].unsqueeze(0))\n",
        "    y_train.append(0)\n",
        "    print(f\"✓ Negative model {i} (label=0)\")\n",
        "\n",
        "X_train = torch.cat(X_train, dim=0)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "\n",
        "print(f\"\\nTraining data shape: X={X_train.shape}, y={y_train.shape}\")\n",
        "print(f\"  Class 1 (positive): {(y_train == 1).sum()} samples\")\n",
        "print(f\"  Class 0 (negative): {(y_train == 0).sum()} samples\\n\")\n",
        "\n",
        "# Train verifier\n",
        "print(\"Training VERIFIER...\")\n",
        "verifier = Verifier(input_dim=X_train.shape[1], hidden_dim=32)\n",
        "optimizer = torch.optim.Adam(verifier.parameters(), lr=0.01)\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "num_epochs = 200\n",
        "for epoch in range(num_epochs):\n",
        "    verifier.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    y_pred = verifier(X_train)\n",
        "    loss = loss_fn(y_pred, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 50 == 0:\n",
        "        print(f\"  Epoch {epoch+1}/{num_epochs} | Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Save verifier\n",
        "verifier_path = base_dir / \"verifier\" / \"verifier.pt\"\n",
        "torch.save(verifier.state_dict(), verifier_path)\n",
        "print(f\"✓ Verifier saved to {verifier_path}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_XoJS60K5oE",
        "outputId": "d6741a08-464f-4461-9cfe-b47bc7e282c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CELL 9: Evaluate Verifier - Calculate TP/TN/Accuracy...\n",
            "======================================================================\n",
            "CONFUSION MATRIX:\n",
            "  TP (True Positive):   3\n",
            "  TN (True Negative):   2\n",
            "  FP (False Positive):  0\n",
            "  FN (False Negative):  0\n",
            "\n",
            "METRICS:\n",
            "  Accuracy:   1.000  (TP+TN)/Total = (3+2)/5\n",
            "  Precision:  1.000  TP/(TP+FP) = 3/(3+0)\n",
            "  Recall:     1.000   TP/(TP+FN) = 3/(3+0)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 9: Evaluate Verifier and Calculate Metrics\n",
        "# ============================================================================\n",
        "print(\"CELL 9: Evaluate Verifier - Calculate TP/TN/Accuracy...\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "verifier.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred_probs = verifier(X_train)\n",
        "    y_pred = (y_pred_probs >= 0.5).long()\n",
        "    y_true = y_train.long()\n",
        "\n",
        "# Calculate confusion matrix\n",
        "TP = ((y_pred == 1) & (y_true == 1)).sum().item()\n",
        "TN = ((y_pred == 0) & (y_true == 0)).sum().item()\n",
        "FP = ((y_pred == 1) & (y_true == 0)).sum().item()\n",
        "FN = ((y_pred == 0) & (y_true == 1)).sum().item()\n",
        "\n",
        "total = len(y_true)\n",
        "accuracy = (TP + TN) / total\n",
        "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "\n",
        "print(\"CONFUSION MATRIX:\")\n",
        "print(f\"  TP (True Positive):   {TP}\")\n",
        "print(f\"  TN (True Negative):   {TN}\")\n",
        "print(f\"  FP (False Positive):  {FP}\")\n",
        "print(f\"  FN (False Negative):  {FN}\")\n",
        "print()\n",
        "print(\"METRICS:\")\n",
        "print(f\"  Accuracy:   {accuracy:.3f}  (TP+TN)/Total = ({TP}+{TN})/{total}\")\n",
        "print(f\"  Precision:  {precision:.3f}  TP/(TP+FP) = {TP}/({TP}+{FP})\")\n",
        "print(f\"  Recall:     {recall:.3f}   TP/(TP+FN) = {TP}/({TP}+{FN})\")\n",
        "print()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
